{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pizza Detector model\n",
    "Ran on AWS EC2 instance using [this AMI](https://github.com/bitfusionio/amis/tree/master/awsmrkt-bfboost-ubuntu14-cuda75-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# image processing imports\n",
    "from keras.preprocessing import image as image_utils \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# modeling imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to images for .flow_from_directory() to pass in images\n",
    "train_data_dir = '/home/ubuntu/data/pizza_class_data/train/'\n",
    "validation_data_dir = '/home/ubuntu/data/pizza_class_data/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing\n",
    "Augments the images via random transformations so the model generalizes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resize images to these dimensions\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# augmented image generator for training set\n",
    "train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=90,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2)\n",
    "\n",
    "# augmented image generator for validation set - really only rescaling here\n",
    "test = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training images\n",
    "The generators are iterators, they returns batches of image samples when requested. You get batches of images (and their labels) by calling the `.flow_from_directory()` function — which automatically labels the data based on folder structure and processes the images to the proper array format for Keras/Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generates training images\n",
    "train_generator = train.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# generates validation images\n",
    "validation_generator = test.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Instantiate model & layers\n",
    "I'll be using four convolutional layers and max-pooling layers plus two fully connected layers. Generally for more complex tasks, you may want more convolutional layers to extract higher and higher level features.\n",
    "\n",
    "###### Convolution layer\n",
    "In a convolutional layer a filter moves across the image and the dot product generates a map of where the feature occurs in the image. This is repeated with different filters (features) to create a stack of filtered images = convolutional layer.\n",
    "\n",
    "**nb_filter:** Number of convolutional kernels (filters) to use = 32\n",
    "- Rough rule for # of filters is the more complex the task, the more filters (but don't need the same number filters for each convolutional layer)\n",
    "\n",
    "**filter_length:** convolution filter size (ie n_conv x n_conv) = 3 \n",
    "- Don't want these too large/small or the resulting matrix might not be very meaningful.  \n",
    "\n",
    "\n",
    "###### ReLU Activation layer\n",
    "Normalizes the feature map weights from the convolutional layers — changes any negative values to zero.\n",
    "\n",
    "\n",
    "###### Pooling layer\n",
    "In a pooling layer a window is moved across filtered images (in strides) and the max value wins, making the filtered images smaller — this is good for performance and also makes the model less sensitive to position.\n",
    "\n",
    "**pool_size:** tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the image in each dimension.\n",
    "- Again shouldn't be too large or lose too much info. \n",
    "- Pooling layer is max pooling, which can be thought of as a “feature detector”\n",
    "\n",
    "**strides:** tuple of 2 integers, or None. The stride value is the amount which the pool size moves across the filtered image in the pooling layer.\n",
    "\n",
    "###### Dropout layer\n",
    "In the dropout layer, hidden & visible units (# of filters/windows in convolutional/pooling layers) are \"dropped\". This is essentially a regularization technique for reducing overfitting.\n",
    "\n",
    "###### (Final) Fully connected layer\n",
    "Stacking the model layers many times, gets the images more filtered & smaller. The final fully connected layer is a single array of weights which “vote” on what the class will be.\n",
    "\n",
    "_**note on dim-ordering:**_ \"tf\" mode means that the images should have shape (samples, width, height, channels), \"th\" mode means that the images should have shape (samples, channels, width, height). Default will be \"tf\" in keras config file.\n",
    "\n",
    "\n",
    "_**note on color:**_ CNN handles 3 channels by transforming the images to YUV color space — which separates out the luminescence (Y component) from the color components (U and V). The luminescence is less important for recognition, since it depends more on the light and less on the object properties, while U and V components are more relevant. The CNN then performs convolution on each of these channels independently in the first convolution layer, and adds the outputs. Then all the color information is encoded and processed by the remaining layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# four convolutional & pooling layers\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# two fully-connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "# sigmoid activation - good for a binary classification\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model\n",
    "\n",
    "Keras will compile the model using whatever backend you have configured (Theano or TensorFlow). Specify the loss function you want to optimize — categorical cross-entropy, which is the standard loss function for multiclass classification because it's well-suited to comparing two probability distributions.\n",
    "\n",
    "Also specify the particular optimization (how different your predicted distribution is from the actual distribution) method to use, rmsprop —  which adapts the learning rate based on how training is going and improves the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure model's learning process\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checkpointing used to output the model weights each time an improvement is observed during training\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model\n",
    "Fit model on data generated batch-by-batch by data generator. Generator runs in parallel to the model, for efficiency — this allows you to do real-time data augmentation on images in parallel to training your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.6748 - acc: 0.5915Epoch 00000: val_acc improved from -inf to 0.72125, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 39s - loss: 0.6754 - acc: 0.5913 - val_loss: 0.5992 - val_acc: 0.7212\n",
      "Epoch 2/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.6251 - acc: 0.6619Epoch 00001: val_acc improved from 0.72125 to 0.73000, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.6257 - acc: 0.6609 - val_loss: 0.5685 - val_acc: 0.7300\n",
      "Epoch 3/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.6006 - acc: 0.6989Epoch 00002: val_acc improved from 0.73000 to 0.77125, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.6021 - acc: 0.6978 - val_loss: 0.5223 - val_acc: 0.7712\n",
      "Epoch 4/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5872 - acc: 0.7105Epoch 00003: val_acc improved from 0.77125 to 0.77375, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.5890 - acc: 0.7091 - val_loss: 0.5479 - val_acc: 0.7738\n",
      "Epoch 5/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.7203Epoch 00004: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.5712 - acc: 0.7188 - val_loss: 0.5006 - val_acc: 0.7650\n",
      "Epoch 6/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5501 - acc: 0.7260Epoch 00005: val_acc improved from 0.77375 to 0.78875, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.5519 - acc: 0.7250 - val_loss: 0.4794 - val_acc: 0.7887\n",
      "Epoch 7/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.7412Epoch 00006: val_acc improved from 0.78875 to 0.79000, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.5409 - acc: 0.7400 - val_loss: 0.4664 - val_acc: 0.7900\n",
      "Epoch 8/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.7576Epoch 00007: val_acc improved from 0.79000 to 0.79875, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.5302 - acc: 0.7562 - val_loss: 0.4595 - val_acc: 0.7987\n",
      "Epoch 9/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5082 - acc: 0.7658Epoch 00008: val_acc improved from 0.79875 to 0.81000, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.5105 - acc: 0.7644 - val_loss: 0.4492 - val_acc: 0.8100\n",
      "Epoch 10/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.7585Epoch 00009: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.5119 - acc: 0.7578 - val_loss: 0.4387 - val_acc: 0.8075\n",
      "Epoch 11/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.5006 - acc: 0.7730Epoch 00010: val_acc improved from 0.81000 to 0.81375, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.5038 - acc: 0.7722 - val_loss: 0.4423 - val_acc: 0.8137\n",
      "Epoch 12/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.7633Epoch 00011: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4987 - acc: 0.7616 - val_loss: 0.4451 - val_acc: 0.8125\n",
      "Epoch 13/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.7746Epoch 00012: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4956 - acc: 0.7744 - val_loss: 0.4518 - val_acc: 0.7800\n",
      "Epoch 14/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.7797Epoch 00013: val_acc improved from 0.81375 to 0.82500, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4886 - acc: 0.7794 - val_loss: 0.4138 - val_acc: 0.8250\n",
      "Epoch 15/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.7907Epoch 00014: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4673 - acc: 0.7906 - val_loss: 0.4012 - val_acc: 0.8163\n",
      "Epoch 16/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4753 - acc: 0.7898Epoch 00015: val_acc improved from 0.82500 to 0.82625, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4756 - acc: 0.7900 - val_loss: 0.3878 - val_acc: 0.8263\n",
      "Epoch 17/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.7876Epoch 00016: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4656 - acc: 0.7866 - val_loss: 0.3985 - val_acc: 0.8150\n",
      "Epoch 18/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.7901Epoch 00017: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4579 - acc: 0.7897 - val_loss: 0.4123 - val_acc: 0.8137\n",
      "Epoch 19/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4475 - acc: 0.8024Epoch 00018: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4519 - acc: 0.8006 - val_loss: 0.4342 - val_acc: 0.8050\n",
      "Epoch 20/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.7926Epoch 00019: val_acc improved from 0.82625 to 0.83750, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4540 - acc: 0.7919 - val_loss: 0.3846 - val_acc: 0.8375\n",
      "Epoch 21/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4467 - acc: 0.8027Epoch 00020: val_acc improved from 0.83750 to 0.84250, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4479 - acc: 0.8019 - val_loss: 0.3955 - val_acc: 0.8425\n",
      "Epoch 22/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8040Epoch 00021: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4409 - acc: 0.8037 - val_loss: 0.4053 - val_acc: 0.8250\n",
      "Epoch 23/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4374 - acc: 0.8103Epoch 00022: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4408 - acc: 0.8094 - val_loss: 0.5006 - val_acc: 0.7212\n",
      "Epoch 24/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4311 - acc: 0.8087Epoch 00023: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4340 - acc: 0.8075 - val_loss: 0.3806 - val_acc: 0.8413\n",
      "Epoch 25/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4282 - acc: 0.8122Epoch 00024: val_acc improved from 0.84250 to 0.85625, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4319 - acc: 0.8106 - val_loss: 0.3896 - val_acc: 0.8562\n",
      "Epoch 26/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4210 - acc: 0.8141Epoch 00025: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4217 - acc: 0.8144 - val_loss: 0.3660 - val_acc: 0.8450\n",
      "Epoch 27/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4228 - acc: 0.8119Epoch 00026: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4241 - acc: 0.8109 - val_loss: 0.3898 - val_acc: 0.8137\n",
      "Epoch 28/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8166Epoch 00027: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4198 - acc: 0.8162 - val_loss: 0.4144 - val_acc: 0.8025\n",
      "Epoch 29/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8213Epoch 00028: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4071 - acc: 0.8216 - val_loss: 0.3672 - val_acc: 0.8462\n",
      "Epoch 30/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4068 - acc: 0.8204Epoch 00029: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4079 - acc: 0.8194 - val_loss: 0.4120 - val_acc: 0.8013\n",
      "Epoch 31/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4184 - acc: 0.8270Epoch 00030: val_acc improved from 0.85625 to 0.86000, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4197 - acc: 0.8263 - val_loss: 0.3497 - val_acc: 0.8600\n",
      "Epoch 32/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4071 - acc: 0.8213Epoch 00031: val_acc improved from 0.86000 to 0.87125, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.4073 - acc: 0.8209 - val_loss: 0.3441 - val_acc: 0.8712\n",
      "Epoch 33/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4149 - acc: 0.8254Epoch 00032: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4166 - acc: 0.8238 - val_loss: 0.4380 - val_acc: 0.8263\n",
      "Epoch 34/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8330Epoch 00033: val_acc did not improve\n",
      "3200/3200 [==============================] - 29s - loss: 0.3966 - acc: 0.8328 - val_loss: 0.3436 - val_acc: 0.8575\n",
      "Epoch 35/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8223Epoch 00034: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4054 - acc: 0.8222 - val_loss: 0.3716 - val_acc: 0.8337\n",
      "Epoch 36/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.4026 - acc: 0.8333Epoch 00035: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.4052 - acc: 0.8316 - val_loss: 0.3879 - val_acc: 0.8213\n",
      "Epoch 37/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8330Epoch 00036: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3944 - acc: 0.8319 - val_loss: 0.3540 - val_acc: 0.8562\n",
      "Epoch 38/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.8453Epoch 00037: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3837 - acc: 0.8444 - val_loss: 0.4205 - val_acc: 0.7863\n",
      "Epoch 39/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8302Epoch 00038: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3961 - acc: 0.8287 - val_loss: 0.3819 - val_acc: 0.8413\n",
      "Epoch 40/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8292Epoch 00039: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3950 - acc: 0.8287 - val_loss: 0.4030 - val_acc: 0.8075\n",
      "Epoch 41/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3950 - acc: 0.8280Epoch 00040: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3955 - acc: 0.8275 - val_loss: 0.3397 - val_acc: 0.8562\n",
      "Epoch 42/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3849 - acc: 0.8374Epoch 00041: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3885 - acc: 0.8363 - val_loss: 0.3776 - val_acc: 0.8387\n",
      "Epoch 43/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8400Epoch 00042: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3890 - acc: 0.8394 - val_loss: 0.3871 - val_acc: 0.8163\n",
      "Epoch 44/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8374Epoch 00043: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3852 - acc: 0.8363 - val_loss: 0.3393 - val_acc: 0.8562\n",
      "Epoch 45/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8318Epoch 00044: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3858 - acc: 0.8309 - val_loss: 0.3663 - val_acc: 0.8363\n",
      "Epoch 46/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3752 - acc: 0.8409Epoch 00045: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3760 - acc: 0.8400 - val_loss: 0.3777 - val_acc: 0.8500\n",
      "Epoch 47/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3814 - acc: 0.8403Epoch 00046: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3831 - acc: 0.8400 - val_loss: 0.3329 - val_acc: 0.8712\n",
      "Epoch 48/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8330Epoch 00047: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3825 - acc: 0.8328 - val_loss: 0.3292 - val_acc: 0.8688\n",
      "Epoch 49/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8343Epoch 00048: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3741 - acc: 0.8344 - val_loss: 0.6426 - val_acc: 0.7250\n",
      "Epoch 50/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8412Epoch 00049: val_acc improved from 0.87125 to 0.87500, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.3825 - acc: 0.8406 - val_loss: 0.3187 - val_acc: 0.8750\n",
      "Epoch 51/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8415Epoch 00050: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3855 - acc: 0.8406 - val_loss: 0.3886 - val_acc: 0.8200\n",
      "Epoch 52/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8425Epoch 00051: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3713 - acc: 0.8416 - val_loss: 0.3361 - val_acc: 0.8662\n",
      "Epoch 53/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8447Epoch 00052: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3798 - acc: 0.8441 - val_loss: 0.3171 - val_acc: 0.8688\n",
      "Epoch 54/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8415Epoch 00053: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3824 - acc: 0.8409 - val_loss: 0.3611 - val_acc: 0.8662\n",
      "Epoch 55/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3717 - acc: 0.8419Epoch 00054: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3721 - acc: 0.8419 - val_loss: 0.3665 - val_acc: 0.8400\n",
      "Epoch 56/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3579 - acc: 0.8434Epoch 00055: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3602 - acc: 0.8425 - val_loss: 0.3198 - val_acc: 0.8700\n",
      "Epoch 57/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3693 - acc: 0.8434Epoch 00056: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3709 - acc: 0.8422 - val_loss: 0.3300 - val_acc: 0.8600\n",
      "Epoch 58/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3716 - acc: 0.8450Epoch 00057: val_acc improved from 0.87500 to 0.87750, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.3739 - acc: 0.8441 - val_loss: 0.3239 - val_acc: 0.8775\n",
      "Epoch 59/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.8422Epoch 00058: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3696 - acc: 0.8416 - val_loss: 0.3206 - val_acc: 0.8725\n",
      "Epoch 60/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8450Epoch 00059: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3637 - acc: 0.8438 - val_loss: 0.3703 - val_acc: 0.8588\n",
      "Epoch 61/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3539 - acc: 0.8520Epoch 00060: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3558 - acc: 0.8512 - val_loss: 0.3882 - val_acc: 0.8087\n",
      "Epoch 62/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3570 - acc: 0.8523Epoch 00061: val_acc improved from 0.87750 to 0.88250, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.3578 - acc: 0.8522 - val_loss: 0.3061 - val_acc: 0.8825\n",
      "Epoch 63/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8516Epoch 00062: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3665 - acc: 0.8519 - val_loss: 0.3181 - val_acc: 0.8738\n",
      "Epoch 64/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3618 - acc: 0.8422Epoch 00063: val_acc improved from 0.88250 to 0.88375, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.3648 - acc: 0.8413 - val_loss: 0.3214 - val_acc: 0.8838\n",
      "Epoch 65/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8510Epoch 00064: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3534 - acc: 0.8509 - val_loss: 0.3596 - val_acc: 0.8375\n",
      "Epoch 66/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3681 - acc: 0.8456Epoch 00065: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3688 - acc: 0.8450 - val_loss: 0.3309 - val_acc: 0.8675\n",
      "Epoch 67/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8485Epoch 00066: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3538 - acc: 0.8481 - val_loss: 0.3593 - val_acc: 0.8337\n",
      "Epoch 68/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.8504Epoch 00067: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3618 - acc: 0.8494 - val_loss: 0.3361 - val_acc: 0.8500\n",
      "Epoch 69/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3562 - acc: 0.8561Epoch 00068: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3567 - acc: 0.8563 - val_loss: 0.3140 - val_acc: 0.8700\n",
      "Epoch 70/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8532Epoch 00069: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3649 - acc: 0.8525 - val_loss: 0.3669 - val_acc: 0.8438\n",
      "Epoch 71/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3627 - acc: 0.8494Epoch 00070: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3644 - acc: 0.8488 - val_loss: 0.3353 - val_acc: 0.8588\n",
      "Epoch 72/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8535Epoch 00071: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3566 - acc: 0.8534 - val_loss: 0.3133 - val_acc: 0.8812\n",
      "Epoch 73/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3573 - acc: 0.8453Epoch 00072: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3607 - acc: 0.8441 - val_loss: 0.3192 - val_acc: 0.8750\n",
      "Epoch 74/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3560 - acc: 0.8586Epoch 00073: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3557 - acc: 0.8578 - val_loss: 0.3516 - val_acc: 0.8662\n",
      "Epoch 75/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3633 - acc: 0.8507Epoch 00074: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3629 - acc: 0.8503 - val_loss: 0.3212 - val_acc: 0.8838\n",
      "Epoch 76/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3491 - acc: 0.8576Epoch 00075: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3502 - acc: 0.8572 - val_loss: 0.3344 - val_acc: 0.8638\n",
      "Epoch 77/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8605Epoch 00076: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3538 - acc: 0.8594 - val_loss: 0.3584 - val_acc: 0.8512\n",
      "Epoch 78/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.8551Epoch 00077: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3507 - acc: 0.8547 - val_loss: 0.4063 - val_acc: 0.8175\n",
      "Epoch 79/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3634 - acc: 0.8542Epoch 00078: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3665 - acc: 0.8538 - val_loss: 0.3426 - val_acc: 0.8612\n",
      "Epoch 80/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3575 - acc: 0.8576Epoch 00079: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3590 - acc: 0.8569 - val_loss: 0.3398 - val_acc: 0.8650\n",
      "Epoch 81/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3629 - acc: 0.8520Epoch 00080: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3625 - acc: 0.8519 - val_loss: 0.3664 - val_acc: 0.8413\n",
      "Epoch 82/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8548Epoch 00081: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3590 - acc: 0.8547 - val_loss: 0.3896 - val_acc: 0.8300\n",
      "Epoch 83/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8570Epoch 00082: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3524 - acc: 0.8569 - val_loss: 0.3150 - val_acc: 0.8662\n",
      "Epoch 84/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.8624Epoch 00083: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3533 - acc: 0.8619 - val_loss: 0.3230 - val_acc: 0.8762\n",
      "Epoch 85/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3559 - acc: 0.8592Epoch 00084: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3558 - acc: 0.8594 - val_loss: 0.3314 - val_acc: 0.8762\n",
      "Epoch 86/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3546 - acc: 0.8507Epoch 00085: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3547 - acc: 0.8509 - val_loss: 0.3227 - val_acc: 0.8738\n",
      "Epoch 87/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3539 - acc: 0.8532Epoch 00086: val_acc improved from 0.88375 to 0.88500, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.3545 - acc: 0.8534 - val_loss: 0.3151 - val_acc: 0.8850\n",
      "Epoch 88/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3527 - acc: 0.8564Epoch 00087: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3543 - acc: 0.8553 - val_loss: 0.3437 - val_acc: 0.8562\n",
      "Epoch 89/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.8551Epoch 00088: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3437 - acc: 0.8541 - val_loss: 0.3668 - val_acc: 0.8375\n",
      "Epoch 90/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.8621Epoch 00089: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3530 - acc: 0.8606 - val_loss: 0.3638 - val_acc: 0.8462\n",
      "Epoch 91/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8526Epoch 00090: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3516 - acc: 0.8522 - val_loss: 0.3438 - val_acc: 0.8375\n",
      "Epoch 92/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8564Epoch 00091: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3491 - acc: 0.8563 - val_loss: 0.3515 - val_acc: 0.8625\n",
      "Epoch 93/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.8535Epoch 00092: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3469 - acc: 0.8525 - val_loss: 0.3437 - val_acc: 0.8550\n",
      "Epoch 94/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.8589Epoch 00093: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3535 - acc: 0.8581 - val_loss: 0.4007 - val_acc: 0.8287\n",
      "Epoch 95/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3583 - acc: 0.8548Epoch 00094: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3593 - acc: 0.8544 - val_loss: 0.3598 - val_acc: 0.8562\n",
      "Epoch 96/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3485 - acc: 0.8520Epoch 00095: val_acc improved from 0.88500 to 0.88625, saving model to weights.best.hdf5\n",
      "3200/3200 [==============================] - 28s - loss: 0.3504 - acc: 0.8509 - val_loss: 0.3180 - val_acc: 0.8862\n",
      "Epoch 97/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.8567Epoch 00096: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3526 - acc: 0.8563 - val_loss: 0.3276 - val_acc: 0.8662\n",
      "Epoch 98/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8539Epoch 00097: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3607 - acc: 0.8531 - val_loss: 0.3085 - val_acc: 0.8738\n",
      "Epoch 99/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3469 - acc: 0.8570Epoch 00098: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3482 - acc: 0.8566 - val_loss: 0.3234 - val_acc: 0.8800\n",
      "Epoch 100/100\n",
      "3168/3200 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.8608Epoch 00099: val_acc did not improve\n",
      "3200/3200 [==============================] - 28s - loss: 0.3429 - acc: 0.8600 - val_loss: 0.3247 - val_acc: 0.8650\n"
     ]
    }
   ],
   "source": [
    "pizza_model = model.fit_generator(\n",
    "    \n",
    "        train_generator,\n",
    "        # number of training samples\n",
    "        samples_per_epoch=3200,\n",
    "    \n",
    "        nb_epoch=100,\n",
    "    \n",
    "        validation_data=validation_generator,\n",
    "        # number of training samples\n",
    "        nb_val_samples=800,\n",
    "        \n",
    "        # lets me save the best models weights\n",
    "        callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to JSON\n",
    "pizza_model_json = model.to_json()\n",
    "with open(\"pizza_model.json\", \"w\") as json_file:\n",
    "    json_file.write(pizza_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights to HDF5\n",
    "model.save_weights(\"pizza_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History\n",
    "History object is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values. It is not part of the model object so you have to pickle it (or use some other method) to use it elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle history object\n",
    "\n",
    "history = pizza_model.history\n",
    "\n",
    "file_Name = \"model_history\"\n",
    "fileObject = open(file_Name,'wb') \n",
    "\n",
    "pickle.dump(history,fileObject)   \n",
    "\n",
    "fileObject.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
